{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1364f4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "cpu count: 32\n"
     ]
    }
   ],
   "source": [
    "import os, sys,shutil, gc\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import math\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import warnings\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timm\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import AdamW,lr_scheduler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from sklearn.metrics import fbeta_score, average_precision_score, roc_auc_score\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "from ink_helpers import (load_image,seed_everything,\n",
    "                         load_fragment,)\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)\n",
    "print(\"cpu count:\", multiprocessing.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dc36282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config:\n",
    "random_seed = 42\n",
    "num_workers = min(12, multiprocessing.cpu_count())\n",
    "\n",
    "bottom_channel_idx = 29\n",
    "top_channel_idx = 35\n",
    "num_fluctuate_channel = 1\n",
    "\n",
    "num_select_channel = top_channel_idx - bottom_channel_idx\n",
    "\n",
    "block_size = 512\n",
    "stride = block_size // 4\n",
    "\n",
    "loss_type = ['bce', 'focal'][0]\n",
    "max_lr = 1.0e-5\n",
    "weight_decay = 1.0e-3\n",
    "total_epoch = 12\n",
    "batch_size = 24\n",
    "\n",
    "valid_id = '2c'\n",
    "\n",
    "\n",
    "seed_everything(seed=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9e7dc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: ['1', '2a', '2b', '3']\n"
     ]
    }
   ],
   "source": [
    "all_frag_ids = ['1', '2a', '2b', '2c', '3']\n",
    "id2dir = {id:f'./frags/train_{id}' for id in all_frag_ids}\n",
    "train_id_list = [id for id in all_frag_ids if id != valid_id]\n",
    "print('Train:', train_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a34b596",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 5/5 [01:13<00:00, 14.71s/it]\n"
     ]
    }
   ],
   "source": [
    "id2images,id2frag_mask,id2ink_mask = {},{},{}\n",
    "for frag_id in tqdm(all_frag_ids):\n",
    "    images,frag_mask,ink_mask = load_fragment(frag_id)\n",
    "    id2images[frag_id] = images\n",
    "    id2frag_mask[frag_id] = frag_mask\n",
    "    id2ink_mask[frag_id] = ink_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dc6e676",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InkDataSet2D(Dataset):\n",
    "    '''\n",
    "    image: (D, H, W); mask: (1, H, W)\n",
    "    '''\n",
    "    def __init__(self, frag_id_list, block_size, channel_slip=0, transforms=None, has_label=True):\n",
    "        self.frag_id_list = frag_id_list\n",
    "        self.block_size = block_size\n",
    "        self.transforms = transforms\n",
    "        self.has_label = has_label\n",
    "        \n",
    "        # get xy positions\n",
    "        id_xybt_list = []\n",
    "        for frag_id in frag_id_list:\n",
    "            frag_mask = id2frag_mask[frag_id]\n",
    "            xy_pairs = [\n",
    "                (min(x,frag_mask.shape[1]-block_size), min(y,frag_mask.shape[0]-block_size))\n",
    "                for x in range(0, frag_mask.shape[1]-block_size+stride, stride) \n",
    "                for y in range(0, frag_mask.shape[0]-block_size+stride, stride) \n",
    "                if np.any(frag_mask[y:y+block_size, x:x+block_size] > 0)\n",
    "            ]\n",
    "            bt_pairs = [(bottom_channel_idx+f, top_channel_idx+f)\n",
    "                        for f in range(-channel_slip, channel_slip+1)]\n",
    "            id_xybt_list += [(frag_id, *xy, *bt) for xy in xy_pairs for bt in bt_pairs]\n",
    "        self.id_xybt_list = id_xybt_list\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.id_xybt_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        frag_id,x,y,start_z,end_z = self.id_xybt_list[idx]\n",
    "\n",
    "        whole_image = id2images[frag_id]\n",
    "        image = whole_image[start_z:end_z, \n",
    "                            y:y+self.block_size, \n",
    "                            x:x+self.block_size] # D,H,W\n",
    "        image = np.moveaxis(image, 0, 2) # H,W,D\n",
    "\n",
    "        if self.has_label:\n",
    "            whole_mask = id2ink_mask[frag_id]\n",
    "            mask = whole_mask[y:y+self.block_size, \n",
    "                              x:x+self.block_size] # H,W\n",
    "            \n",
    "            if self.transforms:\n",
    "                transformed = self.transforms(image=image, mask=mask)\n",
    "                image, mask = transformed['image'], transformed['mask']\n",
    "                \n",
    "            image = np.moveaxis(image, 2, 0) # D,H,W\n",
    "            mask = np.expand_dims(mask, 0) # 1,H,W\n",
    "            \n",
    "            return idx, image, mask\n",
    "        else:\n",
    "            if self.transforms:\n",
    "                image = self.transforms(image=image)['image']\n",
    "            image = np.moveaxis(image, 2, 0) # D,H,W\n",
    "            return idx,image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0a927b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 1004 , Valid 85\n"
     ]
    }
   ],
   "source": [
    "train_transform = A.Compose([\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=1.0),\n",
    "        A.RandomBrightnessContrast(p=0.75),\n",
    "        A.ShiftScaleRotate(p=0.75),\n",
    "        A.OneOf([\n",
    "                A.GaussNoise(var_limit=[10, 50]),\n",
    "                A.GaussianBlur(),\n",
    "                A.MotionBlur(),\n",
    "                ], p=0.4),\n",
    "        A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),\n",
    "        A.CoarseDropout(max_holes=1, max_width=int(block_size * 0.3), max_height=int(block_size * 0.3), \n",
    "                        mask_fill_value=0, p=0.5),\n",
    "        A.Normalize(\n",
    "            mean=[0]*num_select_channel, \n",
    "            std=[1]*num_select_channel\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = InkDataSet2D(\n",
    "    frag_id_list=train_id_list, \n",
    "    block_size=block_size, \n",
    "    channel_slip=num_fluctuate_channel, \n",
    "    transforms=train_transform, \n",
    "    has_label=True\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    pin_memory=True,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers,\n",
    "    prefetch_factor=1,\n",
    ")\n",
    "\n",
    "valid_transform = A.Compose([\n",
    "        A.Normalize(\n",
    "            mean=[0]*num_select_channel, \n",
    "            std=[1]*num_select_channel\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "valid_dataset = InkDataSet2D(\n",
    "    frag_id_list=[valid_id], \n",
    "    block_size=block_size, \n",
    "    channel_slip=0, \n",
    "    transforms=valid_transform, \n",
    "    has_label=False\n",
    ")\n",
    "\n",
    "valid_dataloader = DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=batch_size,\n",
    "    pin_memory=True,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers,\n",
    "    prefetch_factor=1,\n",
    ")\n",
    "\n",
    "print('Train', len(train_dataloader), ', Valid', len(valid_dataloader), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0af4c8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet2D(nn.Module):\n",
    "    def __init__(self, num_channels, num_classes):\n",
    "        super(UNet2D, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.contracting_11 = self.conv_block(in_channels=num_channels, out_channels=64)\n",
    "        self.contracting_12 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.contracting_21 = self.conv_block(in_channels=64, out_channels=128)\n",
    "        self.contracting_22 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.contracting_31 = self.conv_block(in_channels=128, out_channels=256)\n",
    "        self.contracting_32 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.contracting_41 = self.conv_block(in_channels=256, out_channels=512)\n",
    "        self.contracting_42 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.middle = self.conv_block(in_channels=512, out_channels=1024)\n",
    "        self.expansive_11 = nn.ConvTranspose2d(\n",
    "            in_channels=1024,\n",
    "            out_channels=512,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "            output_padding=1,\n",
    "        )\n",
    "        self.expansive_12 = self.conv_block(in_channels=1024, out_channels=512)\n",
    "        self.expansive_21 = nn.ConvTranspose2d(\n",
    "            in_channels=512,\n",
    "            out_channels=256,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "            output_padding=1,\n",
    "        )\n",
    "        self.expansive_22 = self.conv_block(in_channels=512, out_channels=256)\n",
    "        self.expansive_31 = nn.ConvTranspose2d(\n",
    "            in_channels=256,\n",
    "            out_channels=128,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "            output_padding=1,\n",
    "        )\n",
    "        self.expansive_32 = self.conv_block(in_channels=256, out_channels=128)\n",
    "        self.expansive_41 = nn.ConvTranspose2d(\n",
    "            in_channels=128,\n",
    "            out_channels=64,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "            output_padding=1,\n",
    "        )\n",
    "        self.expansive_42 = self.conv_block(in_channels=128, out_channels=64)\n",
    "        self.output = nn.Conv2d(\n",
    "            in_channels=64, out_channels=num_classes, kernel_size=3, stride=1, padding=1\n",
    "        )\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        block = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(num_features=out_channels),\n",
    "            nn.Conv2d(\n",
    "                in_channels=out_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1,\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm2d(num_features=out_channels),\n",
    "        )\n",
    "        return block\n",
    "\n",
    "    def forward(self, X):\n",
    "        contracting_11_out = self.contracting_11(X)  # [-1, 64, 256, 256]\n",
    "        contracting_12_out = self.contracting_12(\n",
    "            contracting_11_out\n",
    "        )  # [-1, 64, 128, 128]\n",
    "        contracting_21_out = self.contracting_21(\n",
    "            contracting_12_out\n",
    "        )  # [-1, 128, 128, 128]\n",
    "        contracting_22_out = self.contracting_22(\n",
    "            contracting_21_out\n",
    "        )  # [-1, 128, 64, 64]\n",
    "        contracting_31_out = self.contracting_31(\n",
    "            contracting_22_out\n",
    "        )  # [-1, 256, 64, 64]\n",
    "        contracting_32_out = self.contracting_32(\n",
    "            contracting_31_out\n",
    "        )  # [-1, 256, 32, 32]\n",
    "        contracting_41_out = self.contracting_41(\n",
    "            contracting_32_out\n",
    "        )  # [-1, 512, 32, 32]\n",
    "        contracting_42_out = self.contracting_42(\n",
    "            contracting_41_out\n",
    "        )  # [-1, 512, 16, 16]\n",
    "        middle_out = self.middle(contracting_42_out)  # [-1, 1024, 16, 16]\n",
    "        expansive_11_out = self.expansive_11(middle_out)  # [-1, 512, 32, 32]\n",
    "        expansive_12_out = self.expansive_12(\n",
    "            torch.cat((expansive_11_out, contracting_41_out), dim=1)\n",
    "        )  # [-1, 1024, 32, 32] -> [-1, 512, 32, 32]\n",
    "        expansive_21_out = self.expansive_21(expansive_12_out)  # [-1, 256, 64, 64]\n",
    "        expansive_22_out = self.expansive_22(\n",
    "            torch.cat((expansive_21_out, contracting_31_out), dim=1)\n",
    "        )  # [-1, 512, 64, 64] -> [-1, 256, 64, 64]\n",
    "        expansive_31_out = self.expansive_31(expansive_22_out)  # [-1, 128, 128, 128]\n",
    "        expansive_32_out = self.expansive_32(\n",
    "            torch.cat((expansive_31_out, contracting_21_out), dim=1)\n",
    "        )  # [-1, 256, 128, 128] -> [-1, 128, 128, 128]\n",
    "        expansive_41_out = self.expansive_41(expansive_32_out)  # [-1, 64, 256, 256]\n",
    "        expansive_42_out = self.expansive_42(\n",
    "            torch.cat((expansive_41_out, contracting_11_out), dim=1)\n",
    "        )  # [-1, 128, 256, 256] -> [-1, 64, 256, 256]\n",
    "        output_out = self.output(expansive_42_out)  # [-1, num_classes, 256, 256]\n",
    "        return output_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6b387c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet2D(num_channels=num_select_channel, num_classes=1);\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f78b5ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 00: 100%|█| 1004/1004 [18:53<00:00,  1.13s/it, LR=9.34e-06, Loss=0.664\n",
      "100%|███████████████████████████████████████| 85/85 [00:41<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: mAP 0.287, AUC 0.650, F0.5 0.272, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 01: 100%|█| 1004/1004 [18:52<00:00,  1.13s/it, LR=9.86e-06, Loss=0.597\n",
      "100%|███████████████████████████████████████| 85/85 [00:42<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: mAP 0.340, AUC 0.689, F0.5 0.348, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 02: 100%|█| 1004/1004 [18:52<00:00,  1.13s/it, LR=9.33e-06, Loss=0.509\n",
      "100%|███████████████████████████████████████| 85/85 [00:42<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: mAP 0.363, AUC 0.699, F0.5 0.389, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 03: 100%|█| 1004/1004 [18:52<00:00,  1.13s/it, LR=8.43e-06, Loss=0.466\n",
      "100%|███████████████████████████████████████| 85/85 [00:41<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: mAP 0.365, AUC 0.705, F0.5 0.388, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 04: 100%|█| 1004/1004 [18:48<00:00,  1.12s/it, LR=7.24e-06, Loss=0.397\n",
      "100%|█████████████████████████████████| 85/85 [00:41<00:00,  2.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: mAP 0.380, AUC 0.715, F0.5 0.394, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 05: 100%|█| 1004/1004 [18:49<00:00,  1.12s/it, LR=5.87e-06, Loss\n",
      "100%|█████████████████████████████████| 85/85 [00:42<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: mAP 0.369, AUC 0.705, F0.5 0.395, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 06: 100%|█| 1004/1004 [18:47<00:00,  1.12s/it, LR=4.42e-06, Loss\n",
      "100%|█████████████████████████████████| 85/85 [00:41<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: mAP 0.377, AUC 0.716, F0.5 0.398, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 07: 100%|█| 1004/1004 [18:50<00:00,  1.13s/it, LR=3.02e-06, Loss\n",
      "100%|███████████████████████████████████| 85/85 [00:41<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: mAP 0.407, AUC 0.735, F0.5 0.418, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 08: 100%|█| 1004/1004 [18:47<00:00,  1.12s/it, LR=1.79e-06, Loss=0\n",
      "100%|███████████████████████████████████| 85/85 [00:41<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: mAP 0.407, AUC 0.729, F0.5 0.430, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 09: 100%|█| 1004/1004 [18:47<00:00,  1.12s/it, LR=8.22e-07, Loss=0\n",
      "100%|███████████████████████████████████| 85/85 [00:41<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid: mAP 0.406, AUC 0.727, F0.5 0.421, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10:   5%| | 47/1004 [00:55<18:40,  1.17s/it, LR=7.85e-07, Loss=0.3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, target)\n\u001b[1;32m     35\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 36\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m     38\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/Projects/dl_env/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:338\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 338\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/Projects/dl_env/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:284\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    283\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf_per_device\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    285\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/Projects/dl_env/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:284\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_maybe_opt_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, optimizer, optimizer_state, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    283\u001b[0m     retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    285\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if loss_type == 'bce':\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "elif loss_type == 'focal':\n",
    "    criterion = FocalLoss(alpha=1, gamma=2, use_logits=True)\n",
    "    \n",
    "optimizer = AdamW(model.parameters(), lr=max_lr, weight_decay=weight_decay)\n",
    "scheduler = lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    epochs=total_epoch,\n",
    "    steps_per_epoch=len(train_dataloader),\n",
    "    max_lr=max_lr,\n",
    "    pct_start=0.1,\n",
    "    anneal_strategy=\"cos\",\n",
    "    div_factor=1.0e3,\n",
    "    final_div_factor=1.0e1,\n",
    ")\n",
    "scaler = GradScaler()\n",
    "Sig = nn.Sigmoid()\n",
    "\n",
    "loss_list = [1] * 10\n",
    "for epoch in range(total_epoch):\n",
    "    \n",
    "    # training\n",
    "    gc.collect()\n",
    "    with tqdm(enumerate(train_dataloader), total=len(train_dataloader)) as pbar:\n",
    "        for step, (idx, img, target) in pbar:\n",
    "            \n",
    "            img, target = img.to(device).float(), target.to(device).float()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            with autocast():\n",
    "                outputs = model(img).float()\n",
    "            loss = criterion(outputs, target)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "\n",
    "            pbar.set_description(f\"Epoch {epoch:02d}\")\n",
    "            loss_list = loss_list[1:] + [loss.item()]\n",
    "            pbar.set_postfix(\n",
    "                OrderedDict(\n",
    "                    LR=f\"{scheduler.get_last_lr()[0]:.2e}\",\n",
    "                    Loss=f\"{sum(loss_list)/10:.4f}\",\n",
    "                )\n",
    "            )\n",
    "            \n",
    "    # validation\n",
    "    valid_frag_mask = id2frag_mask[valid_id]\n",
    "    valid_ink_mask = id2ink_mask[valid_id]\n",
    "    valid_ink_predicts = np.zeros(valid_frag_mask.shape).astype(float)\n",
    "    valid_ink_count = np.zeros(valid_frag_mask.shape)\n",
    "    valid_xybt_list = valid_dataset.id_xybt_list\n",
    "    \n",
    "    model.eval()\n",
    "    for idx, img in tqdm(valid_dataloader):\n",
    "        img = img.to(device).float()\n",
    "        with torch.no_grad():\n",
    "            with autocast():\n",
    "                outputs = Sig(model(img).float())\n",
    "\n",
    "        for batch_idx,whole_idx in enumerate(idx):\n",
    "            x,y = map(int, valid_xybt_list[whole_idx][1:3])\n",
    "\n",
    "            valid_ink_predicts[y:y+block_size, x:x+block_size] += outputs.cpu()[batch_idx][0].numpy()\n",
    "            valid_ink_count[y:y+block_size, x:x+block_size] += 1\n",
    "\n",
    "    valid_ink_count[np.where(valid_frag_mask==0)] = 1\n",
    "    valid_ink_predicts = valid_ink_predicts/valid_ink_count\n",
    "    valid_ink_predicts[np.where(valid_frag_mask==0)] = 0\n",
    "\n",
    "    valid_ink_predicts_flat = valid_ink_predicts[np.where(valid_frag_mask)].flatten()\n",
    "    valid_ink_mask_flat = valid_ink_mask[np.where(valid_frag_mask)].flatten()\n",
    "\n",
    "    map_score = average_precision_score(valid_ink_mask_flat, valid_ink_predicts_flat)\n",
    "    auc_score = roc_auc_score(valid_ink_mask_flat, valid_ink_predicts_flat)\n",
    "    fhalf_score = fbeta_score(valid_ink_mask_flat, valid_ink_predicts_flat>0.5, beta=0.5)\n",
    "    print(f'Valid: mAP {map_score:.3f}, AUC {auc_score:.3f}, F0.5 {fhalf_score:.3f}, ')\n",
    "    model.train()\n",
    "        \n",
    "# save weights\n",
    "torch.save(\n",
    "    model.state_dict(), \n",
    "    f'./weights/2DUNet-block{block_size}-channel{bottom_channel_idx}-to{top_channel_idx}'\n",
    "    f'-slip{num_fluctuate_channel}-loss{loss_type}-lr{max_lr}-wd{weight_decay}-bs{batch_size}'\n",
    "    f'-valid{valid_id}-step{total_epoch*len(train_dataloader)}-seed{random_seed}-epoch{total_epoch}.pth'\n",
    ")\n",
    "    \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444714a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, use_logits=False, reduce=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.use_logits = use_logits\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        if self.use_logits:\n",
    "            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduce=False)\n",
    "        else:\n",
    "            BCE_loss = F.binary_cross_entropy(inputs, targets, reduce=False)\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduce:\n",
    "            return torch.mean(F_loss)\n",
    "        else:\n",
    "            return F_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba929e1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.imshow(valid_ink_mask)\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.imshow(valid_ink_predicts>0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
